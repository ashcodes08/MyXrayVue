{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator as idg\n",
    "from keras.layers import Dropout\n",
    "import math\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D,Dropout, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "keras.__version__\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import cv2\n",
    "\n",
    "import imageio as im\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from os import listdir\n",
    "tf.keras.preprocessing.image.load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = np.array([[890,52 ],\n",
    "                   [73,1402]])\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=binary1)\n",
    "plot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir= \"/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database\"\n",
    "os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuberculosis_data= \"/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis\"\n",
    "print(\"tuberculosis images :\\n\" ,os.listdir(tuberculosis_data)[:5])\n",
    "\n",
    "normal_data= \"/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal\"\n",
    "print(\"\\nnormal images :\\n\" ,os.listdir(normal_data)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"no. of tuberculosis images :\" ,len(os.listdir(tuberculosis_data)))\n",
    "print(\"\\nno. of normal images :\" ,len(os.listdir(normal_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows= 5\n",
    "ncols= 6\n",
    "pic_index= 0\n",
    "\n",
    "fig= plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "pic_index+=8\n",
    "\n",
    "tuberculosis_img = [os.path.join(tuberculosis_data, image) for image in os.listdir(tuberculosis_data)[pic_index-8:pic_index]]\n",
    "normal_img = [os.path.join(normal_data, image) for image in os.listdir(normal_data)[pic_index-8:pic_index]]\n",
    "\n",
    "for i, image_path in enumerate(tuberculosis_img+normal_img):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') \n",
    "\n",
    "    img = mpimg.imread(image_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating training data\n",
    "# Define base directory for dataset\n",
    "base_dir = \"/kaggle/input/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database\"\n",
    "\n",
    "# Generating training data\n",
    "print(\"Training data:\")\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, zoom_range=0.2, width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, shear_range=0.2, \n",
    "                                   horizontal_flip=True, validation_split=0.2)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(base_dir, \n",
    "                                              target_size=(64,64),\n",
    "                                              class_mode=\"binary\",\n",
    "                                              batch_size=32,\n",
    "                                              subset=\"training\"\n",
    "                                              )\n",
    "\n",
    "# Generating validation data\n",
    "print(\"\\nValidation data:\")\n",
    "val_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "\n",
    "val_data = val_datagen.flow_from_directory(base_dir, \n",
    "                                           target_size=(64,64),\n",
    "                                           class_mode=\"binary\",\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=False,\n",
    "                                           subset=\"validation\"\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64,64,3))) #firstlayer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (9, 9), activation='relu',input_shape=(64,64,3))) #secondlayer\n",
    "model.add(layers.MaxPooling2D((4, 4)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 64)) \n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, validation_data=val_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=2)\n",
    "prediction= (prediction > 0.5)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=val_data.classes\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=val_data.classes\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "cm= confusion_matrix(val_data.classes, prediction)\n",
    "plot_confusion_matrix(cm, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(val_data.classes, prediction))\n",
    "print(classification_report(val_data.classes, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(64,64,3))) #firstlayer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(64,64,3))) #firstlayer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (6, 6), activation='relu',input_shape=(64,64,3))) #firstlayer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (6, 6), activation='relu',padding=\"same\",input_shape=(64,64,3))) #secondlayer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu', input_dim = 64)) \n",
    "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, validation_data=val_data, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model.predict(val_data, steps=np.ceil(val_data.samples/val_data.batch_size), verbose=2)\n",
    "prediction= (prediction > 0.5)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=val_data.classes\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "cm= confusion_matrix(val_data.classes, prediction)\n",
    "plot_confusion_matrix(cm, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(val_data.classes, prediction))\n",
    "print(classification_report(val_data.classes, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move(\"my_cnn_model.h5\", \"/kaggle/working/my_cnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
